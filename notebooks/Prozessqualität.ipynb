{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellierung der Vorhersage der Prozessqualität\n",
    "\n",
    "\n",
    "Dieses Notebook beschäftigt sich mit der Entwicklung von Vorhersagemodellen für die Zielgröße. Hierzu werden verschiedene Featuresets und Modelle verwendet, um die bestmögliche Vorhersagegenauigkeit zu erreichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einstellungen und Datenvorbereitung\n",
    "\n",
    "- **Import relevanter Bibliotheken**\n",
    "- **Metrik:** Die Leistung der Modelle wird anhand der `f1` bzw. `f1_weighted`-Metriken bewertet.\n",
    "- **Zielgröße (Target):** `Ergebnis_con`\n",
    "- **Irrelevante Spalten:** Diese Spalten werden aus dem Feature-Set entfernt, da sie für die Vorhersage nicht benötigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from IPython.display import display, HTML\n",
    "from helpers.model_utils import (load_and_prepare_data, \n",
    "                                 display_top_models_for_target, \n",
    "                                 train_and_tune_models_balanced,  \n",
    "                                 compare_results_across_datasets, \n",
    "                                 display_final_confusion_matrices, \n",
    "                                 save_scores_to_csv, \n",
    "                                 analyze_model_performance, \n",
    "                                 filter_and_retrain_with_vif,\n",
    "                                 direcetion_results,\n",
    "                                 plot_scores_and_percent_diff,\n",
    "                                 compare_smote_effects)\n",
    "from helpers.model_pipelines import (define_pipelines_Prozessqualitaet, \n",
    "                                     shap_analysis,load_and_split_data,\n",
    "                                     shap_analysis_single_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einstellungen Notebook\n",
    "target_name = \"Prozessqualität\"\n",
    "\n",
    "# Metrik auswählen\n",
    "metric = \"f1_weighted\"  \n",
    "\n",
    "# Zielgröße\n",
    "target_column = 'Ergebnis_con'  \n",
    "irrelevant_columns = ['Material_con', 'Position_con', 'Probenhoehe', 'richtig_verbaut', 'Zeit', 'VersuchID','umformzeit', 'synthetisch'\n",
    "                      ]\n",
    "\n",
    "# Einfluss der Verkippungssensoren\n",
    "verkippungsfeatures = [\"Verkippung_1\", \"Verkippung_2\", \"Verkippung_3\", \"Verkippung_4\", \n",
    "                      \"Verkippung_1_Min\", \"Verkippung_1_Max\", \"Verkippung_1_Mean\", \"Verkippung_1_Median\", \"Verkippung_1_Std\", \n",
    "                      \"Verkippung_2_Min\",\"Verkippung_2_Max\",\"Verkippung_2_Mean\",\"Verkippung_2_Median\",\"Verkippung_2_Std\",\"Verkippung_3_Min\",\n",
    "                      \"Verkippung_3_Max\",\"Verkippung_3_Mean\",\"Verkippung_3_Median\",\"Verkippung_3_Std\",\"Verkippung_4_Min\",\"Verkippung_4_Max\",\n",
    "                      \"Verkippung_4_Mean\",\"Verkippung_4_Median\",\"Verkippung_4_Std\", \"tilt_x_tiefster\", \"tilt_y_tiefster\", \"tilt_x_t0\", \"tilt_y_t0\"]\n",
    "\n",
    "# Mapping Pfad für Labels\n",
    "label_mapping_path = \"../data_preparation/mappings/label_mappings_binary.json\"\n",
    "\n",
    "# Verkippung berücksichtigen?\n",
    "Verkippung = True\n",
    "if not Verkippung:\n",
    "    irrelevant_columns.extend(verkippungsfeatures)\n",
    "    \n",
    "# SHAP Analyse für ALLE Modelle durchführen?\n",
    "shap_on = False\n",
    "plot_type = 'summary'  # Alternativ: \"summary\", \"bar\" oder \"interaction\" oder \"violin\"\n",
    "plot_type = str(plot_type)\n",
    "\n",
    "# Plots speichern?\n",
    "save_plots = True\n",
    "\n",
    "# mit SMOTE (synthethische Erweiterung der Trainingsdaten)?\n",
    "smote_on = False\n",
    "\n",
    "# Bautiel Temperatur berücksichtigen?\n",
    "bauteil_temp = True\n",
    "if not bauteil_temp:\n",
    "    irrelevant_columns.append('Bauteil_Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfade zu den balancierten Testdaten\n",
    "test_filepath = f\"../datasets/test_{target_column}.pkl\"\n",
    "if smote_on:\n",
    "    # Pfade zu den balancierten Trainingsdaten\n",
    "    train_filepath = f\"../datasets/train_balanced_{target_column}_smote_2500.pkl\"\n",
    "    test_filepath = f\"../datasets/test_{target_column}.pkl\"\n",
    "    # Lade und bereite Trainings- und Testdaten vor\n",
    "    X_train_original, y_train = load_and_prepare_data(train_filepath, target_column, irrelevant_columns)\n",
    "    X_test_original, y_test = load_and_prepare_data(test_filepath, target_column, irrelevant_columns)\n",
    "else: \n",
    "    filepath = f\"../datasets/new_features.pkl\"\n",
    "    X, y = load_and_split_data(filepath, target_column, irrelevant_columns)\n",
    "    # Datenaufteilung\n",
    "    X_train_original, X_test_original, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    \n",
    "# Überprüfen der Shapes\n",
    "print(f\"Trainingsdaten: X_train={X_train_original.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Testdaten: X_test={X_test_original.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "# Zentrale Pipeline und Parameter\n",
    "target_pipeline = define_pipelines_Prozessqualitaet()\n",
    "pipelines, param_grids = target_pipeline\n",
    "\n",
    "# Cross-Validation Setup\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Anzeige der Klassenverteilungen \n",
    "print(\"Klassenverteilung im Training:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nKlassenverteilung im Test:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_original.columns)\n",
    "print(len(X_train_original.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Features Dataset\n",
    "\n",
    "In diesem Abschnitt wird das Datenset für die Prozessmerkmale vorbereitet und trainiert. Das Dataset wird angepasst, indem irrelevante Spalten entfernt und die relevanten Features extrahiert werden. Anschließend werden verschiedene Machine-Learning-Modelle trainiert, die darauf abzielen, die Zielgröße basierend auf den Prozessmerkmalen vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einstellungen Dataset\n",
    "dataset_name = \"process_features\"\n",
    "\n",
    "target_dir, feature_importance_path, balance_suffix, feature_importance_path_best, target_dir_best, tilt_suffix, temp_suffix = direcetion_results(dataset_name, target_name, smote_on, Verkippung, bauteil_temp)\n",
    "\n",
    "# Auswahl der Process Features aus dem Dataset\n",
    "columns_process_features = [\n",
    "    \"VersuchID\",\n",
    "    \"Berührzeit\",\n",
    "    \"Höhe_Wegmessung_Aufprall\",\n",
    "    \"Umformzeit\",\n",
    "    \"Tiefster_Punkt\",\n",
    "    \"Energie_Aufprall\",\n",
    "    \"Motorstrom_Durchschnitt\",\n",
    "    \"Energie_ab_Durchschnitt\",\n",
    "    \"Bauteil_Temp\",\n",
    "    \"Werkzeug_Temp\",\n",
    "    \"Material_con\",\n",
    "    \"Position_con\",\n",
    "    \"Ergebnis_con\",\n",
    "    \"Probenhoehe\",\n",
    "]\n",
    "\n",
    "# Sicherstellen, dass nur existierende Spalten verwendet werden\n",
    "columns_to_keep_train = [col for col in columns_process_features if col in X_train_original.columns]\n",
    "\n",
    "# X_train und X_test auf relevante Spalten beschränken\n",
    "X_train = X_train_original[columns_to_keep_train]\n",
    "X_test = X_test_original[columns_to_keep_train]\n",
    "\n",
    "# Falls Fehler auftreten, können wir sicherstellen, dass alle Spalten korrekt bereinigt sind:\n",
    "X_train.columns = X_train.columns.str.strip()  # Entferne führende und nachfolgende Leerzeichen\n",
    "X_test.columns = X_test.columns.str.strip()\n",
    "\n",
    "print(\"Bereinigte Spalten in X_train:\", X_train.columns)\n",
    "print(\"Bereinigte Spalten in X_test:\", X_test.columns)\n",
    "print(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "In diesem Abschnitt wird das Training der Modelle durchgeführt. Die Modelle werden mit Hilfe von Cross-Validation optimiert, um eine robuste Bewertung der Modellleistung sicherzustellen. Hyperparameter-Tuning wird genutzt, um die besten Einstellungen für jedes Modell zu finden und die Generalisierungsfähigkeit auf Testdaten zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelltraining und Bewertung\n",
    "best_pipelines, results, confusion_matrices1 = train_and_tune_models_balanced(\n",
    "    pipelines, \n",
    "    param_grids, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    skf, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "# Ergebnisse in DataFrame speichern\n",
    "results_df_1 = pd.DataFrame.from_dict(results, orient='index').T\n",
    "#results_df.drop(['best_params'], axis=0, inplace=True)\n",
    "\n",
    "# Ergebnisse in tabellarischer Form anzeigen\n",
    "display(HTML(results_df_1.to_html()))\n",
    "\n",
    "#results_df_1.drop(['best_params'], axis=0, inplace=True)\n",
    "# Ergebnisse speichern\n",
    "save_scores_to_csv(\n",
    "    results=results_df_1,  # Direkt das DataFrame übergeben\n",
    "    output_dir=target_dir,    # Zielverzeichnis\n",
    "    file_name=f\"model_scores_{dataset_name}{balance_suffix}.csv\",  # Dateiname\n",
    "    Verkippung=Verkippung    # Flag für Verkippung\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices\n",
    "\n",
    "In diesem Abschnitt werden die Confusion-Matrices der Modelle analysiert. Diese bieten eine detaillierte Übersicht über die Vorhersagegenauigkeit der Modelle und ermöglichen es, Fehlklassifikationen zu identifizieren. Durchschnittliche Confusion-Matrices über alle Cross-Validation-Folds werden erstellt, visualisiert und optional gespeichert, um die Klassifikationsleistung der Modelle besser zu bewerten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisierte durchschnittliche Confusion-Matrices anzeigen\n",
    "display_final_confusion_matrices(\n",
    "    confusion_matrices1,\n",
    "    label_mapping_path=label_mapping_path,\n",
    "    target_column=target_column,  # Zielspalte hinzufügen\n",
    "    target_dir=target_dir,\n",
    "    save_plots=save_plots,\n",
    "    normalize=True,  # Optional\n",
    "    Verkippung=Verkippung\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Test\n",
    "\n",
    "In diesem Abschnitt wird die Überprüfung von Overfitting durch die Analyse von Learning Curves und Validation Curves durchgeführt, um den Bias-Variance-Tradeoff besser zu verstehen. Die `analyze_model_performance` Funktion aus der `model_pipelines.py` führt diese Analysen durch und erstellt entsprechende Plots. Es werden sowohl die Trainingsscores als auch die Testscores über verschiedene Größen des Trainingssets und Hyperparameterbereiche betrachtet, um die Modellstabilität und die Generalisierungsfähigkeit zu bewerten. Dies hilft dabei, die optimale Komplexität der Modelle zu bestimmen und sicherzustellen, dass sie gut auf unbekannte Daten generalisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting überprüfen \n",
    "# Analyse von Learning Curves für Bias-Variance-Tradeoff\n",
    "print(f\"\\nLearning Curve Analyse für {target_name}:\")\n",
    "\n",
    "# Analyse der Modellleistung\n",
    "analyze_model_performance(\n",
    "    pipelines=pipelines, \n",
    "    param_grids=param_grids, \n",
    "    X=X_train, \n",
    "    y=y_train, \n",
    "    scoring='f1', \n",
    "    cv=skf,\n",
    "    save_plots=save_plots,\n",
    "    output_dir= target_dir,\n",
    "    Verkippung=Verkippung\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP-Analyse\n",
    "\n",
    "In diesem Abschnitt führen wir eine SHAP-Analyse durch, um die Einflüsse der einzelnen Features auf die Vorhersagen der besten Modelle zu verstehen. Die Ergebnisse dieser Analyse helfen uns, die Modellentscheidungen transparenter zu machen. Anschließend laden wir Diagramme, die die besten drei Modelle basierend auf unterschiedlichen Metriken darstellen. Diese Visualisierungen unterstützen die Bewertung der Modellperformance und die Identifizierung von Schlüsselfeatures, die die Zielgröße beeinflussen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP-Analyse\n",
    "if shap_on:\n",
    "    shap_analysis(\n",
    "    best_pipelines=best_pipelines,  # Das Dictionary der besten Pipelines\n",
    "    X_train=X_train,  # Die Trainingsdaten\n",
    "    target_name = target_name,  # Der Zielname, z. B. für das Modellieren des Zielwerts\n",
    "    dataset_name= dataset_name,  # Der Name des Datensets\n",
    "    output_dir= target_dir,  # Optional: Basisverzeichnis für die Ergebnisse\n",
    "    plot_type=plot_type,\n",
    "    save_plots=save_plots,  # Angabe, ob die Diagramme gespeichert werden sollen\n",
    "    verkippung = Verkippung\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if shap_on:\n",
    "#     feature_importances, irrelevant_features = extract_feature_importance_from_shap(\n",
    "#         best_pipelines=best_pipelines,\n",
    "#         X_train=X_train,\n",
    "#         target_name=target_name,\n",
    "#         dataset_name=dataset_name,\n",
    "#         output_dir=target_dir,\n",
    "#         verkippung=Verkippung,\n",
    "#         importance_threshold=0.01,\n",
    "#         save_results=save_plots\n",
    "#     )\n",
    "\n",
    "#     # Ausgabe der irrelevanten Features\n",
    "#     print(\"Irrelevante Features:\", irrelevant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregierte Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einstellungen\n",
    "dataset_name = \"aggregated_features\"\n",
    "\n",
    "target_dir, feature_importance_path, balance_suffix, feature_importance_path_best, target_dir_best, tilt_suffix, temp_suffix = direcetion_results(dataset_name, target_name, smote_on, Verkippung, bauteil_temp)\n",
    "\n",
    "# Auswahl der Process Features aus dem Dataset\n",
    "columns_aggregated_features = [\n",
    "    \"VersuchID\",\n",
    "    \"Berührzeit\",\n",
    "    \"Höhe_Wegmessung_Aufprall\",\n",
    "    \"Umformzeit\",\n",
    "    \"Tiefster_Punkt\",\n",
    "    \"Energie_Aufprall\",\n",
    "    \"Motorstrom_Durchschnitt\",\n",
    "    \"Energie_ab_Durchschnitt\",\n",
    "    \"Bauteil_Temp\",\n",
    "    \"Werkzeug_Temp\",\n",
    "    \"Material_con\",\n",
    "    \"Position_con\",\n",
    "    \"Ergebnis_con\",\n",
    "    \"Probenhoehe\",\n",
    "    \"richtig_verbaut\",\n",
    "    \"Wegmessung_Min\",\n",
    "    \"Wegmessung_Max\",\n",
    "    \"Wegmessung_Mean\",\n",
    "    \"Wegmessung_Median\",\n",
    "    \"Wegmessung_Std\",\n",
    "    \"Verkippung_1_Min\",\n",
    "    \"Verkippung_1_Max\",\n",
    "    \"Verkippung_1_Mean\",\n",
    "    \"Verkippung_1_Median\",\n",
    "    \"Verkippung_1_Std\",\n",
    "    \"Verkippung_2_Min\",\n",
    "    \"Verkippung_2_Max\",\n",
    "    \"Verkippung_2_Mean\",\n",
    "    \"Verkippung_2_Median\",\n",
    "    \"Verkippung_2_Std\",\n",
    "    \"Verkippung_3_Min\",\n",
    "    \"Verkippung_3_Max\",\n",
    "    \"Verkippung_3_Mean\",\n",
    "    \"Verkippung_3_Median\",\n",
    "    \"Verkippung_3_Std\",\n",
    "    \"Verkippung_4_Min\",\n",
    "    \"Verkippung_4_Max\",\n",
    "    \"Verkippung_4_Mean\",\n",
    "    \"Verkippung_4_Median\",\n",
    "    \"Verkippung_4_Std\",\n",
    "    \"Stoesselhub_Min\",\n",
    "    \"Stoesselhub_Max\",\n",
    "    \"Stoesselhub_Mean\",\n",
    "    \"Stoesselhub_Median\",\n",
    "    \"Stoesselhub_Std\",\n",
    "    \"Geschwindigkeit_Ges_Min\",\n",
    "    \"Geschwindigkeit_Ges_Max\",\n",
    "    \"Geschwindigkeit_Ges_Mean\",\n",
    "    \"Geschwindigkeit_Ges_Median\",\n",
    "    \"Geschwindigkeit_Ges_Std\",\n",
    "    \"Presskraft_dyn_Min\",\n",
    "    \"Presskraft_dyn_Max\",\n",
    "    \"Presskraft_dyn_Mean\",\n",
    "    \"Presskraft_dyn_Median\",\n",
    "    \"Presskraft_dyn_Std\",\n",
    "    \"Motorstrom_Min\",\n",
    "    \"Motorstrom_Max\",\n",
    "    \"Motorstrom_Mean\",\n",
    "    \"Motorstrom_Median\",\n",
    "    \"Motorstrom_Std\",\n",
    "]\n",
    "\n",
    "# Sicherstellen, dass nur existierende Spalten verwendet werden\n",
    "columns_to_keep_train = [col for col in columns_aggregated_features if col in X_train_original.columns]\n",
    "\n",
    "# X_train und X_test auf relevante Spalten beschränken\n",
    "X_train = X_train_original[columns_to_keep_train]\n",
    "X_test = X_test_original[columns_to_keep_train]\n",
    "\n",
    "# Falls Fehler auftreten, können wir sicherstellen, dass alle Spalten korrekt bereinigt sind:\n",
    "X_train.columns = X_train.columns.str.strip()  # Entferne führende und nachfolgende Leerzeichen\n",
    "X_test.columns = X_test.columns.str.strip()\n",
    "\n",
    "print(\"Bereinigte Spalten in X_train:\", X_train.columns)\n",
    "print(\"Bereinigte Spalten in X_test:\", X_test.columns)\n",
    "print(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelltraining und Bewertung\n",
    "best_pipelines, results, confusion_matrices2 = train_and_tune_models_balanced(pipelines, \n",
    "    param_grids, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    skf, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "# Ergebnisse in DataFrame speichern\n",
    "results_df_2 = pd.DataFrame.from_dict(results, orient='index').T\n",
    "#results_df.drop(['best_params'], axis=0, inplace=True)\n",
    "\n",
    "# Ergebnisse in tabellarischer Form anzeigen\n",
    "display(HTML(results_df_2.to_html()))\n",
    "\n",
    "save_scores_to_csv(\n",
    "    results=results_df_2,  # DataFrame mit den Scores\n",
    "    output_dir=target_dir,\n",
    "    file_name=f\"model_scores_{dataset_name}{balance_suffix}.csv\",  # Gemeinsamer Basisname\n",
    "    Verkippung=Verkippung  # Fügt den '_no_tilt'-Suffix hinzu, falls nötig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisierte durchschnittliche Confusion-Matrices anzeigen\n",
    "display_final_confusion_matrices(\n",
    "    confusion_matrices2,\n",
    "    label_mapping_path=label_mapping_path,\n",
    "    target_column=target_column,  # Zielspalte hinzufügen\n",
    "    target_dir=target_dir,\n",
    "    save_plots=save_plots,\n",
    "    normalize=True,  # Optional\n",
    "    Verkippung=Verkippung\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting überprüfen \n",
    "# Analyse von Learning Curves für Bias-Variance-Tradeoff\n",
    "print(f\"\\nLearning Curve Analyse für {target_name}:\")\n",
    "\n",
    "# Analyse der Modellleistung\n",
    "analyze_model_performance(\n",
    "    pipelines=pipelines, \n",
    "    param_grids=param_grids, \n",
    "    X=X_train, \n",
    "    y=y_train, \n",
    "    scoring='f1', \n",
    "    cv=skf,\n",
    "    save_plots=save_plots,\n",
    "    output_dir= target_dir,\n",
    "    Verkippung=Verkippung\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP-Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP-Analyse\n",
    "if shap_on:\n",
    "    shap_analysis(\n",
    "    best_pipelines=best_pipelines,  # Das Dictionary der besten Pipelines\n",
    "    X_train=X_train,  # Die Trainingsdaten\n",
    "    target_name = target_name,  # Der Zielname, z. B. für das Modellieren des Zielwerts\n",
    "    dataset_name= dataset_name,  # Der Name des Datensets\n",
    "    output_dir= target_dir,  # Optional: Basisverzeichnis für die Ergebnisse\n",
    "    plot_type=plot_type,\n",
    "    save_plots=save_plots,  # Angabe, ob die Diagramme gespeichert werden sollen\n",
    "    verkippung = Verkippung\n",
    ")\n",
    "    #starting_shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einstellungen\n",
    "dataset_name = \"new_features\"\n",
    "\n",
    "target_dir, feature_importance_path, balance_suffix, feature_importance_path_best, target_dir_best, tilt_suffix, temp_suffix = direcetion_results(dataset_name, target_name, smote_on, Verkippung, bauteil_temp)\n",
    "\n",
    "# X_train und X_test auf relevante Spalten beschränken\n",
    "X_train = X_train_original\n",
    "X_test = X_test_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelltraining und Bewertung\n",
    "best_pipelines, results, confusion_matrices3 = train_and_tune_models_balanced(pipelines, \n",
    "    param_grids, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    skf, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    ")\n",
    "\n",
    "# Ergebnisse in DataFrame speichern\n",
    "results_df_3 = pd.DataFrame.from_dict(results, orient='index').T\n",
    "#results_df.drop(['best_params'], axis=0, inplace=True)\n",
    "\n",
    "# Ergebnisse in tabellarischer Form anzeigen\n",
    "display(HTML(results_df_3.to_html()))\n",
    "\n",
    "save_scores_to_csv(\n",
    "    results=results_df_3,  # DataFrame mit den Scores\n",
    "    output_dir=target_dir,\n",
    "    file_name=f\"model_scores_{dataset_name}{balance_suffix}.csv\",  # Gemeinsamer Basisname\n",
    "    Verkippung=Verkippung  # Fügt den '_no_tilt'-Suffix hinzu, falls nötig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisierte durchschnittliche Confusion-Matrices anzeigen\n",
    "display_final_confusion_matrices(\n",
    "    confusion_matrices3,\n",
    "    label_mapping_path=label_mapping_path,\n",
    "    target_column=target_column,  # Zielspalte hinzufügen\n",
    "    target_dir=target_dir,\n",
    "    save_plots=save_plots,\n",
    "    normalize=True,  # Optional\n",
    "    Verkippung=Verkippung\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse von Learning Curves für Bias-Variance-Tradeoff\n",
    "print(f\"\\nLearning Curve Analyse für {target_name}:\")\n",
    "\n",
    "# Analyse der Modellleistung\n",
    "analyze_model_performance(\n",
    "    pipelines=pipelines, \n",
    "    param_grids=param_grids, \n",
    "    X=X_train, \n",
    "    y=y_train, \n",
    "    scoring='f1', \n",
    "    cv=skf,\n",
    "    save_plots=save_plots,\n",
    "    output_dir= target_dir,\n",
    "    Verkippung=Verkippung\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP-Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP-Analyse\n",
    "if shap_on:\n",
    "    shap_analysis(\n",
    "    best_pipelines=best_pipelines,  # Das Dictionary der besten Pipelines\n",
    "    X_train=X_train,  # Die Trainingsdaten\n",
    "    target_name = target_name,  # Der Zielname, z. B. für das Modellieren des Zielwerts\n",
    "    dataset_name= dataset_name,  # Der Name des Datensets\n",
    "    output_dir= target_dir,  # Optional: Basisverzeichnis für die Ergebnisse\n",
    "    plot_type=plot_type,\n",
    "    save_plots=save_plots,  # Angabe, ob die Diagramme gespeichert werden sollen\n",
    "    verkippung = Verkippung\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich der Results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = {\n",
    "    \"Process Features\": results_df_1,\n",
    "    \"Aggregated Features\": results_df_2,\n",
    "    \"New Features\": results_df_3\n",
    "}\n",
    "\n",
    "# Vergleich der Ergebnisse über die Datasets hinweg\n",
    "compare_metric = \"f1_weighted\"\n",
    "comparison_table, best_combination = compare_results_across_datasets(results_dfs, metric=\"f1\")\n",
    "\n",
    "# Vergleichstabelle in HTML-Format konvertieren und anzeigen\n",
    "print(f\"Vergleich der {compare_metric}-Scores für die unterschiedlichen Datasets und Modelle:\")\n",
    "display(HTML(comparison_table.to_html()))\n",
    "\n",
    "# Beste Kombination ausgeben\n",
    "print(f\"\\nBeste Kombination:\")\n",
    "print(f\"Dataset: {best_combination[0]}, Modell: {best_combination[1]}, Score: {best_combination[2]:.4f}\")\n",
    "\n",
    "save_scores_to_csv(\n",
    "    results=comparison_table,\n",
    "    output_dir=target_dir,\n",
    "    file_name=f\"compare_model_scores_{target_name}_{compare_metric}.csv\",\n",
    "    Verkippung=Verkippung\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f\"../results/{target_name}/{balance_suffix}{tilt_suffix}{temp_suffix}/compare_model_scores_{target_name}_{compare_metric}{balance_suffix}{tilt_suffix}{temp_suffix}.svg\"\n",
    "\n",
    "# Diagramm erstellen\n",
    "plot_scores_and_percent_diff(results_dfs, target_name=target_name, output_path=output_path, y_lim=(0.7, 1.0), metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduktion der Features & Performance des Best Models\n",
    "- Das beste Modell wird nach der Feature Reduktion mit Hilfe der SHAP Values im Zielverzeichis gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell und Feature Datensatz auswählen\n",
    "model_name = \"kNN\"\n",
    "pipeline = best_pipelines[model_name]\n",
    "dataset_name = \"new_features\"\n",
    "\n",
    "target_dir, feature_importance_path, balance_suffix, feature_importance_path_best, target_dir_best, tilt_suffix, temp_suffix  = direcetion_results(dataset_name, target_name, smote_on, Verkippung, bauteil_temp, model_name=model_name)\n",
    "\n",
    "# Verzeichnis erstellen, falls es nicht existiert\n",
    "os.makedirs(target_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP-Analyse für ein einzelnes Modell\n",
    "# shap_analysis_single_model(\n",
    "#     model_name=model_name,\n",
    "#     pipeline=pipeline,\n",
    "#     X_train=X_train,\n",
    "#     target_name=target_name,\n",
    "#     dataset_name=dataset_name,\n",
    "#     output_dir=target_dir_best,\n",
    "#     plot_type=plot_type,\n",
    "#     save_plots=save_plots,\n",
    "#     verkippung=Verkippung\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importance_path_best = f\"results/best_models/{target_name}/feature_importance_{model_name}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **AUFRUF DER FUNKTION**\n",
    "best_pipelines, retrain_results = filter_and_retrain_with_vif(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    feature_importance_path=feature_importance_path_best,\n",
    "    param_grids=param_grids,\n",
    "    cv=skf,\n",
    "    scoring=metric,\n",
    "    pareto_split=0.8,  \n",
    "    correlation_threshold=0.9,  \n",
    "    vif_threshold=200.0,  \n",
    "    output_dir=target_dir_best,\n",
    "    target_name=target_name,\n",
    "    dataset_name=dataset_name,\n",
    "    verkippung=Verkippung,\n",
    "    is_regression=False,\n",
    "    label_mapping_path=label_mapping_path,    # Neuer Parameter für Confusion-Matrix\n",
    "    target_column=target_column          # Neuer Parameter für Confusion-Matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisierung der Ergebnisse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE für Prozess Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_path = f\"../results/{target_name}/{tilt_suffix}{temp_suffix}/process_features/model_scores_process_features.csv\"\n",
    "no_smote_path = f\"../results/{target_name}/{balance_suffix}{tilt_suffix}{temp_suffix}/process_features/model_scores_process_featuresnoSMOTE.csv\"\n",
    "output_path = f\"../results/{target_name}/compare_SMOTE_process_features_{target_name}_{compare_metric}.svg\"\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "df_comp = compare_smote_effects(no_smote_path, smote_path, metric=\"f1\", title=f\"Vergleich der Fehlermetrik für das Prozess Feature-Set: No SMOTE vs. SMOTE\", save_path=output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
